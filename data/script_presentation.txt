import statement:

numbpy -> arrays
pandas : dataframes are selected
seaborn : eda
matplotlib : eda / visualization
nltk : natural lang tool kit

see other stemmers -> snowblall stemmer

toktoktokennizer - >The tok-tok tokenizer is a simple, general tokenizer, 
where the input has one sentence per line; thus only final period is tokenized. 
Tok-tok has been tested on, and gives reasonably good results for English,


MATPLOTLIB :
fig(8,6)  -> hight and breadth
couting the descriptions fr each risk

df.isnull() -> checking for null values in each feature -> ans is given in boolean

df.dropna -> dropna() function return Index without NA/NaN values. 
All the missing values are removed and a new object is returned which does not have 
any NaN values present in it. 
If the Index is a MultiIndex, drop the value when any or all levels are NaN.


label encoding heading:
Encode the object as an enumerated type or categorical variable. 
This method is useful for obtaining a numeric representation of an array
[:200} --> making all equal to 200

TFIDF -> see later. for eahc sentence it aplhabetically gives a number

ch2 ->uingrams and bigrams


MACHINE LEARNING:

model.fit(x_train_tfidf,y_train1) ->training model where we take 2 inputs on basis of x we shud get y 

labelbinarizer  : to convert data to binary when multple outputs are required 

count vector is where each word in a sentence is represented using a word-index vector
and if we supply a new sentence using transform() it gives a count

But if a word is unique to only certain sentences cuont vectroizer cuases problems hence:
 
tfidf helps us find the words frequesnt in a text setnece array.
if a word is unique to a sentence it is given priority or it is highlighted
